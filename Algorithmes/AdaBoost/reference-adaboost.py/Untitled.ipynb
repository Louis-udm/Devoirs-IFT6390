{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "\n",
    "#通过比较阈值进行分类\n",
    "#threshVal是阈值 threshIneq决定了不等号是大于还是小于\n",
    "def stumpClassify(dataMatrix,dimen,threshVal,threshIneq):\n",
    "\n",
    "    retArray = ones((shape(dataMatrix)[0],1)) #先全部设为1\n",
    "    if threshIneq == 'lt':  #然后根据阈值和不等号将满足要求的都设为-1\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n",
    "    return retArray\n",
    "\n",
    "#在加权数据集里面寻找最低错误率的单层决策树\n",
    "#D是指数据集权重 用于计算加权错误率\n",
    "def buildStump(dataArr,classLabels,D):\n",
    "    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T\n",
    "    m,n = shape(dataMatrix)  #m为行数 n为列数\n",
    "    numSteps = 10.0; bestStump = {}; bestClasEst = mat(zeros((m,1)))\n",
    "    minError = inf #最小误差率初值设为无穷大\n",
    "    for i in range(n):  #第一层循环 对数据集中的每一个特征 n为特征总数\n",
    "        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max()\n",
    "        stepSize = (rangeMax-rangeMin)/numSteps\n",
    "        for j in range(-1,int(numSteps)+1): #第二层循环 对每个步长\n",
    "            for inequal in ['lt','gt']: #第三层循环 对每个不等号\n",
    "                threshVal = rangeMin + float(j) * stepSize#计算阈值\n",
    "                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)#根据阈值和不等号进行预测\n",
    "                errArr = mat(ones((m,1)))#先假设所有的结果都是错的（标记为1）\n",
    "                errArr[predictedVals == labelMat] = 0#然后把预测结果正确的标记为0\n",
    "                weightedError = D.T*errArr#计算加权错误率 \n",
    "                #print 'split: dim %d, thresh %.2f, thresh inequal: %s, \\\n",
    "                #        the weightederror is %.3f' % (i,threshVal,inequal,weightedError)\n",
    "                if weightedError < minError:    #将加权错误率最小的结果保存下来\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump, minError, bestClasEst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#加载数据集\n",
    "def loadSimpleData():\n",
    "    dataMat = matrix([[1.,2.1],\n",
    "                         [2.,1.1],\n",
    "                         [1.3,1.],\n",
    "                         [1.,1.],\n",
    "                         [2.,1.]])\n",
    "    classLabels = [1.0,1.0,-1.0,-1.0,1.0]\n",
    "    return dataMat,classLabels\n",
    "\n",
    "#绘制数据集\n",
    "def pltData(dataMat,classLabels):\n",
    "    for index,item in enumerate(dataMat):   #enumrate的参数为一个可以遍历的东西，返回值为索引和该项\n",
    "        if classLabels[index] > 0:\n",
    "            plt.plot(item[0,0],item[0,1],'or')  #'or' 表示 画红点\n",
    "        else:\n",
    "            plt.plot(item[0,0],item[0,1],'ob')  #'ob' 表示 画蓝点\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#基于单层决策树的AdaBoost训练函数\n",
    "#numIt指迭代次数 默认为40 当训练错误率达到0就会提前结束训练\n",
    "def adaBoostTrainDS(dataArr,classLabels,numIt=40):\n",
    "    weakClassArr = []   #用于存储每次训练得到的弱分类器以及其输出结果的权重\n",
    "    m = shape(dataArr)[0]\n",
    "    D = mat(ones((m,1))/m)  #数据集权重初始化为1/m\n",
    "    aggClassEst = mat(zeros((m,1))) #记录每个数据点的类别估计累计值\n",
    "    for i in range(numIt):\n",
    "        bestStump,error,classEst = buildStump(dataArr,classLabels,D)#在加权数据集里面寻找最低错误率的单层决策树\n",
    "        #print \"D: \",D.T\n",
    "        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))#根据错误率计算出本次单层决策树输出结果的权重 max(error,1e-16)则是为了确保error为0时不会出现除0溢出\n",
    "        bestStump['alpha'] = alpha#记录权重\n",
    "        weakClassArr.append(bestStump)\n",
    "        #print 'classEst: ',classEst.T\n",
    "        #计算下一次迭代中的权重向量D\n",
    "        expon = multiply(-1*alpha*mat(classLabels).T,classEst)#计算指数\n",
    "        D = multiply(D,exp(expon))\n",
    "        D = D/D.sum()#归一化\n",
    "        #错误率累加计算\n",
    "        aggClassEst += alpha*classEst\n",
    "        #print 'aggClassEst: ',aggClassEst.T\n",
    "        #aggErrors = multiply(sign(aggClassEst)!=mat(classLabels).T,ones((m,1)))\n",
    "        #errorRate = aggErrors.sum()/m\n",
    "        errorRate = 1.0*sum(sign(aggClassEst)!=mat(classLabels).T)/m#sign(aggClassEst)表示根据aggClassEst的正负号分别标记为1 -1\n",
    "        print 'total error: ',errorRate\n",
    "        if errorRate == 0.0:#如果错误率为0那就提前结束for循环\n",
    "            break\n",
    "    return weakClassArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#基于AdaBoost的分类函数\n",
    "#dataToClass是待分类样例 classifierArr是adaBoostTrainDS函数训练出来的弱分类器数组\n",
    "def adaClassify(dataToClass,classifierArr):\n",
    "    dataMatrix = mat(dataToClass)\n",
    "    m = shape(dataMatrix)[0]\n",
    "    aggClassEst = mat(zeros((m,1)))\n",
    "    for i in range(len(classifierArr)): #遍历所有的弱分类器\n",
    "        classEst = stumpClassify(dataMatrix,classifierArr[i]['dim'],\\\n",
    "                                 classifierArr[i]['thresh'],\\\n",
    "                                 classifierArr[i]['ineq'])\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst\n",
    "        #print aggClassEst\n",
    "    return sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#自适应数据加载函数\n",
    "def loadDataSet(fileName):\n",
    "    numFeat = len(open(fileName).readline().split('\\t'))\n",
    "    dataMat = []; labelMat = []\n",
    "    for line in open(fileName).readlines():\n",
    "        lineArr = []\n",
    "        curLine = line.strip().split('\\t')\n",
    "        for i in range(numFeat-1):  #最后一项为label\n",
    "            lineArr.append(float(curLine[i]))\n",
    "        dataMat.append(lineArr)\n",
    "        labelMat.append(curLine[-1])\n",
    "    return dataMat,labelMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louis/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:29: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "in the future, 0-d boolean arrays will be interpreted as a valid boolean index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c00917035c5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#训练分类器\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataArr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelArr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloadDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'horseColicTraining2.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassifierArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaBoostTrainDS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataArr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelArr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#测试\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtestArr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestLabelArr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'horseColicTest2.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5e35975a426d>\u001b[0m in \u001b[0;36madaBoostTrainDS\u001b[0;34m(dataArr, classLabels, numIt)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maggClassEst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#记录每个数据点的类别估计累计值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumIt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mbestStump\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassEst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildStump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataArr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassLabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#在加权数据集里面寻找最低错误率的单层决策树\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m#print \"D: \",D.T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#根据错误率计算出本次单层决策树输出结果的权重 max(error,1e-16)则是为了确保error为0时不会出现除0溢出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-8c47c328b0e4>\u001b[0m in \u001b[0;36mbuildStump\u001b[0;34m(dataArr, classLabels, D)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mpredictedVals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstumpClassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataMatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshVal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minequal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#根据阈值和不等号进行预测\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0merrArr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#先假设所有的结果都是错的（标记为1）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0merrArr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictedVals\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabelMat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;31m#然后把预测结果正确的标记为0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mweightedError\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0merrArr\u001b[0m\u001b[0;31m#计算加权错误率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m#print 'split: dim %d, thresh %.2f, thresh inequal: %s, \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: in the future, 0-d boolean arrays will be interpreted as a valid boolean index"
     ]
    }
   ],
   "source": [
    "#训练分类器\n",
    "dataArr,labelArr=loadDataSet('horseColicTraining2.txt')\n",
    "classifierArray = adaBoostTrainDS(dataArr,labelArr,10)\n",
    "#测试\n",
    "testArr, testLabelArr = loadDataSet('horseColicTest2.txt')\n",
    "prediction10 = adaClassify(testArr,classifierArray)\n",
    "print 1.0*sum(prediction10!=mat(testLabelArr).T)/len(prediction10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
